@book{wickham_grolemund2017,
author= {Hadley Wickham and Garrett Grolemund},
titel = {R for Data Science},
publisher = {O'Reilly},
year = {2017},
address = {Sebastopol, CA},
url = {http://r4ds.had.co.nz/}}


@incollection{obrien_2014,
     author = {David O'Brien},
	Booktitle = {Internet Monitor 2014: Reflections on the Digital World: Platforms, Policy, Privacy, and Public Discourse},
	Editor = {Urs Gasser and Jonathan Zittrain and Robert Faris and Rebekah Heacock
Jones},
Series = {Berkman Center Research Publication},
Number = {No. 2014-17},
	Publisher = {Berkman Center for Internet \& Society at Harvard University},
  title = {{In the Age of the Web, What Does ``Public'' Mean?}},
	Year = {2014},
	URL = {https://dash.harvard.edu/bitstream/handle/1/13632937/IM2014_ReflectionsontheDigitalWorld%5B1%5D.pdf}}


@misc{sintef_2013,
author = {SINTEF},
  title = {{Big Data, for better or worse: 90% of world's data generated over last two years.}},
  journal = {ScienceDaily},
  howpublished = {\url{www.sciencedaily.com/releases/2013/05/130522085217.htm}},
  note = {Accessed: 2017-09-13},
  year = {2014}
}


@techreport{markham_buchanan2012,
    author = {Markham, Annette and Buchanan, Elizabeth},
    year = {2012},
    title = {Ethical Decision-Making and Internet Research: Recommendations from the AoIR Ethics Working Committee (Version 2.0)},
    institution = {Association of Internet Researchers},
    type = {Report},
    url= {http://aoir.org/reports/ethics2.pdf}
}


Ethical Decision-Making and Internet Research: Recommendations from the AOIR Ethics Committee
Approved by the Ethics Working Committee (Version 2.0), 08/2012.

@book{sunstein_2002,
  title={Republic.com},
  author={Sunstein, C.R.},
  isbn={9780691095899},
  lccn={00045331},
  url={https://books.google.ch/books?id=O7AG9TxDJdgC},
  year={2002},
  publisher={Princeton University Press}
}


@inproceedings{adamic_glance2005,
 author = {Adamic, Lada A. and Glance, Natalie},
 title = {{The Political Blogosphere and the 2004 U.S. Election: Divided They Blog}},
 booktitle = {Proceedings of the 3rd International Workshop on Link Discovery},
 series = {LinkKDD '05},
 year = {2005},
 isbn = {1-59593-215-1},
 location = {Chicago, Illinois},
 pages = {36--43},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1134271.1134277},
 doi = {10.1145/1134271.1134277},
 acmid = {1134277},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {link analysis, political blogs, social networks},
} 


@techreport{matter_2016,
    author = {Matter, Ulrich},
    year = {2016},
    title = {RWebData: A High-Level Interface to the Programmable Web},
    institution = {arXiv preprint},
    type = {stat.CO},
    number = {arXiv:1603.00293},
    note = {([Abstract](https://arxiv.org/abs/1603.00293), [Code](https://bitbucket.org/ulrich-matter/rwebdata))},
    pdf = {https://www.cesifo-group.de/DocDL/cesifo1_wp6007_0.pdf}
    }

@incollection{swartz_2013,
	Author = {Aaron Swartz},
	Booktitle = {Synthesis Lectures on The Semantic Web: Theory and Technology},
	Date-Added = {2014-06-13 14:50:57 +0000},
	Date-Modified = {2014-06-13 15:15:58 +0000},
	Editor = {James Hendler and Ying Ding},
	Publisher = {Morgan \& Claypool Publishers},
	Title = {Aaron Swartz's A Programmable Web: An Unfinished Work},
	Year = {2013}}


@article{edelman_2012,
    author = {Edelman, Benjamin},
    journal = {Journal of Economic Perspectives},
    title = {Using Internet Data for Economic Research},
    year = {2012},
    volume = {26},
    url = {http://dx.doi.org/10.1257/jep.26.2.189},
    pages = {189-206},
    number = {2},
    doi = {10.1257/jep.26.2.189}
    }

@article{einav_levin2014,
        author = {Einav, Liran and Levin, Jonathan},
        journal = {Science},
        title = {Economics in the Age of Big
       Data},
        year = {2014},
        volume = {346},
        url = {http://dx.doi.org/10.1126/science.1243089},
        pages = {1243089-1–1243089-6},
        number = {6210},
        doi = {10.1126/science.1243089}
        }

@article{matter_stutzer2015,
    author = {Ulrich Matter and Stutzer, Alois},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {{pvsR: An Open Source Interface to Big Data on the American Political Sphere}},
    year = {2015},
    month = {07},
    volume = {10},
    url = {http://dx.doi.org/10.1371%2Fjournal.pone.0130501},
    pages = {1-21},
    number = {7},
    doi = {10.1371/journal.pone.0130501},
    note = {([R package](https://cran.r-project.org/web/packages/pvsR/index.html), [Code](https://github.com/umatter/pvsR), [Blogpost](http://www.bitss.org/2016/08/07/open-source-interfaces-with-the-programmable-web-facilitate-replications-of-big-data-analyses-in-social-science-research/))},
    pdf = {http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0130501&type=printable}
}


@book{russel_2014,
author = {Russel, Mathew A.},
title = {Mining the Social Web},
year = {2014},
address = {Sebastopol, CA},
publisher = {O'Reilly}}

@book{nolan_lang2014,
author = {Deborah Nolan and Duncan Temple Lang},
title = {XML and Web Technologies for Data Sciences with R},
year = {2014},
address = {New York, NY},
publisher = {Springer-Verlag},
url = {http://www.rxmlwebtech.org/}}

@book{bing_2011,
author = {Liu, Bing},
title = {Web Data Mining},
address = {New York, NY},
publisher = {Springer},
year  = {2011}}

@book{mitchell_2015,
author = {Ryan Mitchell},
year = {2015},
title = {Web Scraping with Python},
address = {Sebastopol, CA},
publisher = {O'Reilly}}

@book{munzert_etal2014,
author = {Munzert, S. and Rubba, C. and Meißner, P. and Nyhuis, D. },
title = {Automated Data Collection with R: A Practical Guide to Web Scraping and Text Mining},
year = {2014},
address = {Chichester, UK},
publisher = {Wiley}}


@techreport{matter2016,
    author = {Matter, Ulrich},
    year = {2016},
    title = {RWebData: A High-Level Interface to the Programmable Web},
    institution = {arXiv preprint},
    type = {stat.CO},
    number = {arXiv:1603.00293},
    note = {([Abstract](https://arxiv.org/abs/1603.00293), [Code](https://bitbucket.org/ulrich-matter/rwebdata))},
    pdf = {https://www.cesifo-group.de/DocDL/cesifo1_wp6007_0.pdf}
    }


@techreport{roberts_etal2011,
    author = {Hal Roberts and David Larochelle and Rob Faris and John Palfrey},
    year = {2011},
    title = {Mapping Local Internet Control},
    institution = {Berkman Center for Internet \& Society at Harvard University},
    url = {http://cyber.harvard.edu/netmaps/mlic_20110513.pdf}
    }
    
@techreport{ackermann_etal2017,
    author = {Ackermann, Klaus and Angus, Simon D. and  Raschky, Paul A.},
    year = {2017},
    title = {The Internet as Quantitative Social Science Platform: Insights from a Trillion Observations},
    institution = {arxiv.org},
    number = {arXiv:1701.05632v1 [q-fin.EC]},
    url = {https://arxiv.org/pdf/1701.05632.pdf}
    }
    
    
    
@article{bajari_hortacsu2003,
 ISSN = {07416261},
 URL = {http://www.jstor.org/stable/1593721},
 abstract = {Internet auctions have recently gained widespread popularity and are one of the most successful forms of electronic commerce. We examine a unique dataset of eBay coin auctions to explore the determinants of bidder and seller behavior. We first document a number of empirical regularities. We then specify and estimate a structural econometric model of bidding on eBay. Using our parameter estimates from this model, we measure the extent of the winner's curse and simulate seller revenue under different reserve prices.},
 author = {Patrick Bajari and Ali Hortaçsu},
 journal = {The RAND Journal of Economics},
 number = {2},
 pages = {329-355},
 title = {The Winner's Curse, Reserve Prices, and Endogenous Entry: Empirical Insights from eBay Auctions},
 volume = {34},
 year = {2003}
}




@article{cavallo_2016,
author = {Alberto Cavallo},
title = {Scraped Data and Sticky Prices},
journal = {The Review of Economics and Statistics},
volume = {0},
number = {ja},
pages = {null},
year = {2016},
doi = {10.1162/REST\_a\_00652},

URL = { 
        https://doi.org/10.1162/REST_a_00652
    
},
eprint = { 
        https://doi.org/10.1162/REST_a_00652
    
}
,
    abstract = { Abstract I use daily prices collected from online retailers in five countries to study the impact of measurement bias on three common price stickiness statistics. Relative to previous results, I find that online prices have longer durations, with fewer price changes close to zero, and hazard functions that initially increase over time. I show that time-averaging and imputed prices in scanner and CPI data can fully explain the differences with the literature. I then report summary statistics for the duration and size of price changes using scraped data collected from 181 retailers in 31 countries. JEL Classifications: E30, E31. }
}



@article{antweiler_frank2004,
 ISSN = {00221082, 15406261},
 URL = {http://www.jstor.org/stable/3694736},
 abstract = {Financial press reports claim that Internet stock message boards can move markets. We study the effect of more than 1.5 million messages posted on Yahoo! Finance and Raging Bull about the 45 companies in the Dow Jones Industrial Average and the Dow Jones Internet Index. Bullishness is measured using computational linguistics methods. Wall Street Journal news stories are used as controls. We find that stock messages help predict market volatility. Their effect on stock returns is statistically significant but economically small. Consistent with Harris and Raviv (1993), disagreement among the posted messages is associated with increased trading volume.},
 author = {Werner Antweiler and Murray Z. Frank},
 journal = {The Journal of Finance},
 number = {3},
 pages = {1259-1294},
 title = {Is All That Talk Just Noise? The Information Content of Internet Stock Message Boards},
 volume = {59},
 year = {2004}
}



@article{ginsberg_etal2009,
	title = {Detecting influenza epidemics using search engine query data},
	volume = {457},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/nature07634},
	doi = {10.1038/nature07634},
	number = {7232},
	journal = {Nature},
	author = {Ginsberg, Jeremy and Mohebbi, Matthew H. and Patel, Rajan S. and Brammer, Lynnette and Smolinski, Mark S. and Brilliant, Larry},
	month = feb,
	year = {2009},
	pages = {1012--1014}
}



@Article{chevalier_2003,
author="Chevalier, Judith
and Goolsbee, Austan",
title="Measuring Prices and Price Competition Online: Amazon.com and BarnesandNoble.com",
journal="Quantitative Marketing and Economics",
year="2003",
month="Jun",
day="01",
volume="1",
number="2",
pages="203--222",
abstract="Despite the interest in measuring price sensitivity of online consumers, most academic work on Internet commerce is hindered by a lack of data on quantity. In this paper we use publicly available data on the sales ranks of about 20,000 books to derive quantity proxies at the two leading online booksellers. Matching this information to prices, we can directly estimate the elasticities of demand facing both merchants as well as create a price index for online books. The results show significant price sensitivity at both merchants but demand at BarnesandNoble.com is much more price-elastic than is demand at Amazon.com. The data also allow us to estimate the magnitude of bias in the CPI due to the rise of Internet sales.",
issn="1573-711X",
doi="10.1023/A:1024634613982",
url="https://doi.org/10.1023/A:1024634613982"
}




@article{khalil_fakir2017,
title = "RCrawler: An R package for parallel web crawling and scraping ",
journal = "SoftwareX",
volume = "6",
number = "",
pages = "98 - 106",
year = "2017",
note = "",
issn = "2352-7110",
doi = "https://doi.org/10.1016/j.softx.2017.04.004",
url = "https://www.sciencedirect.com/science/article/pii/S2352711017300110",
author = "Salim Khalil and Mohamed Fakir",
keywords = "Web crawler",
keywords = "Web scraper",
keywords = "R package",
keywords = "Parallel crawling",
keywords = "Web mining",
keywords = "Data collection ",
abstract = "Abstract \{RCrawler\} is a contributed R package for domain-based web crawling and content scraping. As the first implementation of a parallel web crawler in the R environment, \{RCrawler\} can crawl, parse, store pages, extract contents, and produce data that can be directly employed for web content mining applications. However, it is also flexible, and could be adapted to other applications. The main features of \{RCrawler\} are multi-threaded crawling, content extraction, and duplicate content detection. In addition, it includes functionalities such as \{URL\} and content-type filtering, depth level controlling, and a robot.txt parser. Our crawler has a highly optimized system, and can download a large number of pages per second while being robust against certain crashes and spider traps. In this paper, we describe the design and functionality of RCrawler, and report on our experience of implementing it in an R environment, including different optimizations that handle the limitations of R. Finally, we discuss our experimental results. "
}





@article{arthur_2014,
     title = "Facebook emotion study breached ethical guidelines, researchers say",
     Journal = "Guardian",
     year = "2014",
     day = "30",
     month = "06",
     url = {https://www.theguardian.com/technology/2014/jun/30/facebook-emotion-study-breached-ethical-guidelines-researchers-say"},
     author = "Charles Arthur"
}

@article{kramer_etal2014,
     title = "Experimental evidence of massive-scale emotional contagion through social networks",
     journal = "PNAS",
     author = "Kramer, Adam D.I. and Jamie E. Guillory and Jeffrey T. Hancock",
     volume = "111",
     number = "24",
     year = "2014",
     url = "http://www.pnas.org/content/111/24/8788.full.pdf"
}


@article{iovino_2017,
     author = "Iovino, Nicholas",
     title = "LinkedIn Lawsuit Against Data-Scraper Has Wide Implications",
     journal = "Courthouse News Service",
     year = "2017",
     month = "07",
     day = "28",
     url = "https://www.courthousenews.com/linkedin-lawsuit-data-scraper-wide-implications/"}

@article{giles_2010,
author= {Giles, Jim},
title = {Data sifted from Facebook wiped after legal threats},
year = {2010},
month = {03},
day = {31},
url = {https://www.newscientist.com/article/dn18721-data-sifted-from-facebook-wiped-after-legal-threats/},
journal = {New Scientist}
}



@article{snell_menaldo2016,
author = {James Snell and Nicola Menaldo},
title = {Web Scraping in an Era of Big Data 2.0},
year = {2016},
month = {June},
day = {8},
journal = {Bloomberg Law},
url = {https://www.bna.com/web-scraping-era-n57982073780/}}


@inproceedings{morstatter_etal2014,
 author = {Morstatter, Fred and Pfeffer, J\"{u}rgen and Liu, Huan},
 title = {When is It Biased?: Assessing the Representativeness of Twitter's Streaming API},
 booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
 series = {WWW '14 Companion},
 year = {2014},
 isbn = {978-1-4503-2745-9},
 location = {Seoul, Korea},
 pages = {555--556},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2567948.2576952},
 doi = {10.1145/2567948.2576952},
 acmid = {2576952},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {big data, data sampling, sampling bias, twitter analysis},
} 



@inbook{morstatter_etal2013,
title = "Is the sample good enough? Comparing data from twitter's streaming API with Twitter's firehose",
abstract = "Twitter is a social media giant famous for the exchange of short, 140-character messages called {"}tweets{"}. In the scientific community, the microblogging site is known for openness in sharing its data. It provides a glance into its millions of users and billions of tweets through a {"}Streaming API{"} which provides a sample of all tweets matching some parameters preset by the API user. The API service has been used by many researchers, companies, and governmental institutions that want to extract knowledge in accordance with a diverse array of questions pertaining to social media. The essential drawback of the Twitter API is the lack of documentation concerning what and how much data users get. This leads researchers to question whether the sampled data is a valid representation of the overall activity on Twitter. In this work we embark on answering this question by comparing data collected using Twitter's sampled API service with data collected using the full, albeit costly, Firehose stream that includes every single published tweet. We compare both datasets using common statistical metrics as well as metrics that allow us to compare topics, networks, and locations of tweets. The results of our work will help researchers and practitioners understand the implications of using the Streaming API.",
author = "Fred Morstatter and Jürgen Pfeffer and Huan Liu and Carley, {Kathleen M.}",
year = "2013",
pages = "400--408",
booktitle = "Proceedings of the 7th International Conference on Weblogs and Social Media, ICWSM 2013",
publisher = "AAAI press",

}

@techreport{kelley_etal2013,
title = {Conducting Research on Twitter: A Call for Guidelines and Metrics},
author = {Patrick Gage Kelley and Manya Sleeper and Justin Cranshaw},
year = {2013},
institution = {CSCW Measuring Networked Social Privacy Workshop 2013},
url = {http://patrickgagekelley.com/papers/twitter-pmj.pdf}
}


@article{ginsberg2009detecting,
  title={Detecting influenza epidemics using search engine query data},
  author={Ginsberg, Jeremy and Mohebbi, Matthew H and Patel, Rajan S and Brammer, Lynnette and Smolinski, Mark S and Brilliant, Larry},
  journal={Nature},
  volume={457},
  number={7232},
  pages={1012--1014},
  year={2009},
  publisher={Nature Publishing Group}
}

@article{butler2013,
title = {When Google got flu wrong},
author = {Declan Butler},
volume= {494},
pages = {155},
year = {2013}
}


@techreport{antenucci_etal2014,
 title = "Using Social Media to Measure Labor Market Flows",
 author = "Dolan Antenucci and Michael Cafarella and Margaret Levenstein and Christopher Ré and Matthew D. Shapiro",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "20010",
 year = "2014",
 month = "March",
 doi = {10.3386/w20010},
 URL = "http://www.nber.org/papers/w20010"
}



@article{matter_stutzer2015role,
  title={The Role of Lawyer-Legislators in Shaping the Law: Evidence from Voting on Tort Reforms},
  author={Matter, Ulrich and Stutzer, Alois},
  journal={Journal of Law and Economics},
  volume={58},
  number={2},
  pages={357--384},
  year={2015},
  publisher={University of Chicago Press Chicago, IL}
}


@techreport{katz_matter2017,
 author = {Katz, Yarden and Matter, Ulrich},
 year = {2017},
 title = {On the Biomedical Elite: Inequality and Stasis in Scientific Knowledge Production},
 institution = {Berkman Klein Center for Internet \& Society at Harvard University},
 type = {Berkman Klein Center Research Publication},
 number ={2017-5},
 note = {([Abstract](https://dash.harvard.edu/handle/1/33373356), [Media Coverage: Science Magazine](http://www.sciencemag.org/news/2017/07/relatively-few-nih-grantees-get-lion-s-share-agency-s-funding))},
 pdf = {https://dash.harvard.edu/bitstream/handle/1/33373356/BKC_Report_KatzMatter2017.pdf?sequence=1}
 }

@article {jasny_etal2011,
	author = {Jasny, Barbara R. and Chin, Gilbert and Chong, Lisa and Vignieri, Sacha},
	title = {Again, and Again, and Again {\textellipsis}},
	volume = {334},
	number = {6060},
	pages = {1225--1225},
	year = {2011},
	doi = {10.1126/science.334.6060.1225},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/334/6060/1225},
	eprint = {http://science.sciencemag.org/content/334/6060/1225.full.pdf},
	journal = {Science}
}



@article{dodds_etal2011,
    author = {Dodds, Peter Sheridan and Harris, Kameron Decker and Kloumann, Isabel M. and Bliss, Catherine A. AND Danforth, Christopher M.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Temporal Patterns of Happiness and Information in a Global Social Network: Hedonometrics and Twitter},
    year = {2011},
    month = {12},
    volume = {6},
    url = {https://doi.org/10.1371/journal.pone.0026752},
    pages = {1-1},
    abstract = {Individual happiness is a fundamental societal metric. Normally measured through self-report, happiness has often been indirectly characterized and overshadowed by more readily quantifiable economic indicators such as gross domestic product. Here, we examine expressions made on the online, global microblog and social networking service Twitter, uncovering and explaining temporal variations in happiness and information levels over timescales ranging from hours to years. Our data set comprises over 46 billion words contained in nearly 4.6 billion expressions posted over a 33 month span by over 63 million unique users. In measuring happiness, we construct a tunable, real-time, remote-sensing, and non-invasive, text-based hedonometer. In building our metric, made available with this paper, we conducted a survey to obtain happiness evaluations of over 10,000 individual words, representing a tenfold size improvement over similar existing word sets. Rather than being ad hoc, our word list is chosen solely by frequency of usage, and we show how a highly robust and tunable metric can be constructed and defended.},
    number = {12},
    doi = {10.1371/journal.pone.0026752}
}




@misc{he_rothschild2016,
author = {Ran He and David Rothschild},
  title = {{Selection bias in documenting online conversations}},
  howpublished = {\url{http://researchdmr.com/EntityDetection.pdf}},
  note = {Accessed: 2017-12-12},
  year = {2016}
}




@article {kryvasheyeue_etal2016,
	author = {Kryvasheyeu, Yury and Chen, Haohui and Obradovich, Nick and Moro, Esteban and Van Hentenryck, Pascal and Fowler, James and Cebrian, Manuel},
	title = {Rapid assessment of disaster damage using social media activity},
	volume = {2},
	number = {3},
	year = {2016},
	doi = {10.1126/sciadv.1500779},
	publisher = {American Association for the Advancement of Science},
	abstract = {Could social media data aid in disaster response and damage assessment? Countries face both an increasing frequency and an increasing intensity of natural disasters resulting from climate change. During such events, citizens turn to social media platforms for disaster-related communication and information. Social media improves situational awareness, facilitates dissemination of emergency information, enables early warning systems, and helps coordinate relief efforts. In addition, the spatiotemporal distribution of disaster-related messages helps with the real-time monitoring and assessment of the disaster itself. We present a multiscale analysis of Twitter activity before, during, and after Hurricane Sandy. We examine the online response of 50 metropolitan areas of the United States and find a strong relationship between proximity to Sandy{\textquoteright}s path and hurricane-related social media activity. We show that real and perceived threats, together with physical disaster effects, are directly observable through the intensity and composition of Twitter{\textquoteright}s message stream. We demonstrate that per-capita Twitter activity strongly correlates with the per-capita economic damage inflicted by the hurricane. We verify our findings for a wide range of disasters and suggest that massive online social networks can be used for rapid assessment of damage caused by a large-scale disaster.},
	URL = {http://advances.sciencemag.org/content/2/3/e1500779},
	eprint = {http://advances.sciencemag.org/content/2/3/e1500779.full.pdf},
	journal = {Science Advances}
}

@article{katz_2017,
author = {Katz, Yarden},
title = {{Manufacturing an Artificial Intelligence Revolution}},
year = {2017},
url= {https://ssrn.com/abstract=3078224},
note = {Available on SSRN: \url{https://ssrn.com/abstract=3078224}}
}

@book{hogben_1983,
author = {Lancelot Hogben},
title = {{Mathematics for the Million}},
publisher = {W.W Norton \& Company},
address = {New York},
year = 1983}


@book{murrell_2009,
author = {Paul Murrell},
title = {{Introduction to Data Technologies}},
year = {2009},
publisher = {CRC Press},
address = {London, UK}}
